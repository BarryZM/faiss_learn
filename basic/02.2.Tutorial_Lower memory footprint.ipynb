{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower memory footprint\n",
    "\n",
    "https://github.com/facebookresearch/faiss/wiki/Lower-memory-footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb (100000, 64)\n",
      "xq (10000, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000.\n",
    "print('xb', xb.shape)\n",
    "# print('xb', xb[:1])\n",
    "print('xq', xq.shape)\n",
    "# print('xq', xq[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This uses too much memory, how can I shrink the storage?——IndexIVFPQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IndexFlatL2` 和 `IndexIVFFlat` 都会保存全部的向量. 为了扩展到非常大的数据集，Faiss提供了变通，基于点积量化器（product quantizers）的有损压缩来压缩存储向量。\n",
    "\n",
    "The vectors are still stored in Voronoi cells, but their size is reduced to a configurable number of bytes m (d must be a multiple of m).\n",
    "\n",
    "The compression is based on a Product Quantizer, that can be seen as an additional level of quantization, that is applied on sub-vectors of the vectors to encode.\n",
    "\n",
    "In this case, since the vectors are not stored exactly, the distances that are returned by the search method are also approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   78  608  159]\n",
      " [   1 1063  555  380]\n",
      " [   2  304  134   46]\n",
      " [   3   64  773  265]\n",
      " [   4  288  827  531]]\n",
      "[[1.6157436 6.1152253 6.4348025 6.564184 ]\n",
      " [1.389575  5.6771317 5.9956017 6.486294 ]\n",
      " [1.7025063 6.121688  6.189084  6.489888 ]\n",
      " [1.8057687 6.5440307 6.6684756 6.859398 ]\n",
      " [1.4920276 5.79976   6.190908  6.3791513]]\n",
      "[[ 9900  8746  9853 10437]\n",
      " [10494 10507 11373  9014]\n",
      " [10719 11291 10424 10138]\n",
      " [10122  9638 11113 10630]\n",
      " [ 9229 10304  9644 10370]]\n"
     ]
    }
   ],
   "source": [
    "nlist = 100\n",
    "m = 8                             # number of subquantizers\n",
    "k = 4\n",
    "\n",
    "import faiss\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # this remains the same\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n",
    "                                    # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index.train(xb)\n",
    "index.add(xb)\n",
    "D, I = index.search(xb[:5], k) # sanity check\n",
    "print(I)\n",
    "print(D)\n",
    "index.nprobe = 10              # make comparable with experiment above\n",
    "D, I = index.search(xq, k)     # search\n",
    "print(I[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look like:\n",
    "```text\n",
    "[[   0  608  220  228]\n",
    " [   1 1063  277  617]\n",
    " [   2   46  114  304]\n",
    " [   3  791  527  316]\n",
    " [   4  159  288  393]]\n",
    "```\n",
    "```text\n",
    "[[ 1.40704751  6.19361687  6.34912491  6.35771513]\n",
    " [ 1.49901485  5.66632462  5.94188499  6.29570007]\n",
    " [ 1.63260388  6.04126883  6.18447495  6.26815748]\n",
    " [ 1.5356375   6.33165455  6.64519501  6.86594009]\n",
    " [ 1.46203303  6.5022912   6.62621975  6.63154221]]\n",
    "```\n",
    "We can observe that the nearest neighbor is found correctly (it is the vector ID itself), but the estimated distance of the vector to itself is not 0, although it is significantly lower than the distance to the other neighbors. This is due to the lossy compression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compress 64 32-bit floats to 8 bytes, so the compression factor is 32.\n",
    "\n",
    "When searching on real queries, the results look like:\n",
    "```text\n",
    "[[ 9432  9649  9900 10287]\n",
    " [10229 10403  9829  9740]\n",
    " [10847 10824  9787 10089]\n",
    " [11268 10935 10260 10571]\n",
    " [ 9582 10304  9616  9850]]\n",
    "```\n",
    "They can be compared with the IVFFlat results above. For this case, most results are wrong, but they are in the correct area of the space, as shown by the IDs around 10000. The situation is better for real data because:\n",
    "\n",
    "uniform data is very difficult to index because there is no regularity that can be exploited to cluster or reduce dimensionality\n",
    "\n",
    "for natural data, the semantic nearest neighbor is often significantly closer than irrelevant results.\n",
    "\n",
    "Simplifying index construction\n",
    "Since building indexes can become complicated, there is a factory function that constructs them given a string. The indexes above can be obtained with the following shorthand:\n",
    "```python\n",
    "index = faiss.index_factory(d, \"IVF100,PQ8\")\n",
    "```\n",
    "Replace PQ4 with Flat to get an IndexFlat. The factory is particularly useful when preprocessing (PCA) is applied to the input vectors. For example, the factory string to preprocess reduce the vectors to 32D by PCA projection is: \"PCA32,IVF100,Flat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the next sections to get more specific information about the types of indexes, GPU faiss, coding structure, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
